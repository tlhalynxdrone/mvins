%YAML:1.0

use_gpu: 1
output_path: "/home/tlha/missions/path/"

imu:
   num: 1
   topic: "/imu/data"
   #imu parameters       The more accurate parameters you provide, the better performance
   acc_n: 0.0307750318          # accelerometer measurement noise standard deviation. #0.2
   gyr_n: 0.0013355474         # gyroscope measurement noise standard deviation.     #0.05
   acc_w: 0.0029280328         # accelerometer bias random work noise standard deviation.  #0.02
   gyr_w: 4.071648e-04        # gyroscope bias random work noise standard deviation.     #4.0e-5
   g_norm: 9.805       # gravity magnitude

   center_T_imu: !!opencv-matrix
      rows: 4
      cols: 4
      dt: d
      data: [ 1.0, 0.0, 0.0, -2.0e-02,
            0.0, 1.0, 0.0, 0.0e-02,
            0.0, 0.0, 1.0, 1.0e-02, 0.0, 0.0, 0.0, 1.0 ]

cam_module:
    num: 1
    modules:
      - cam_id: orbbec
        depth: 0
        stereo: 0
        image_width: 640
        image_height: 480
        image0_topic: "/camera/color/image_raw"
        depth0_topic: "/camera/depth/image_raw"
        cam0_calib: "orbbec_calib_640x480.yaml"
       
        td: -0.02525464172208901                                 # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)
        rolling_shutter: 0                      # 0: global shutter camera, 1: rolling shutter camera
        rolling_shutter_tr: 0.03333               # unit: s. rolling shutter read out time per frame (from data sheet). 

        imu_T_cam0: !!opencv-matrix
            rows: 4
            cols: 4
            dt: d
            data: [  0.00456087, -0.01966287,  0.99979626,  0.11987105, 
                    -0.9999821,  -0.00396099,  0.00448382,  0.0296931,
                    0.00387201, -0.99979882, -0.01968058, -0.00048338,
                    0.0000000,   0.0000000,   0.0000000,   1.0000000]

  

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.
                        # 2  Don't know anything about extrinsic parameters. You don't need to give R,T. We will try to calibrate it. Do some rotation movement at beginning.                        
#If you choose 0 or 1, you should write down the following matrix.
#Rotation from camera frame to imu frame, imu^R_cam

multiple_thread: 1
#feature traker paprameters
max_cnt: 200           #200   # max feature number in feature tracking
min_dist: 10                 # min distance between two features
freq: 20              #10    # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image
F_threshold: 1.0              # ransac threshold (pixel)
show_track: 1         #1     # publish tracking image as topic
flow_back: 1             # perform forward and backward optical flow to improve feature tracking accuracy
equalize: 1            #0     # if image is too dark or light, trun on equalize to find enough features
fisheye: 0             #0     # if using fisheye, trun on it. A circle mask will be loaded to remove edge noisy points
use_fast: 1                   # if it equals to 1, we extract and track fast feature, otherwise we use GFTT from opencv
use_rgbd: 1           #0     # if using rgbd camera, turn on it. Depth residuals will be added to sliding window optimization and initialization
min_fast_resp: 7              # min response of fast feature


#optimization parameters
max_solver_time: 0.08         # max solver itration time (ms), to guarantee real time
max_num_iterations: 8      #8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0       # keyframe selection threshold (pixel)
reproj_threshold: 5.0



#loop closure parameters
loop_closure: 1                    # start loop closure
fast_relocalization: 1             # useful in real-time and large project
load_previous_pose_graph: 0        # load and reuse previous pose graph; load from 'pose_graph_save_path'
pose_graph_save_path: "/home/tlha/missions/pose_graph/" # save and load path
save_image: 0                   # save image in pose graph for visualization prupose; you can close this function by setting 0 

#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu


